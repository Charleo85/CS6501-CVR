{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Lab.\n",
    "\n",
    "In this lab we will continue working with the CIFAR-10 dataset. However, we will go deeper. Adding linear layers and non-linear activations functions on top of each other. First, I will present a re-implementation of what we had last time.\n",
    "\n",
    "### 1. Implementing our own Softmax + CrossEntropyLoss function.\n",
    "This is similar to the loss_softmax and loss_softmax_backward implementations in the previous lab. Here we also make sure this works for a batch of vectors instead of a single vector. This means the input here will be a tensor of size batchSize x inputSize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch, lab_utils, random\n",
    "from torchvision.datasets import CIFAR10 \n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json, string\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This class combines Softmax + Cross Entropy Loss.\n",
    "# Similar to the previous lab, but this implementation works for batches of inputs and\n",
    "# not just individual input vectors. Here the input is batchSize x inputSize.\n",
    "class nn_CrossEntropyLoss(object): \n",
    "    # Forward pass -log softmax(input_{label})\n",
    "    def forward(self, inputs, labels):\n",
    "        max_val = inputs.max()  # This is to avoid variable overflows.\n",
    "        exp_inputs = (inputs - max_val).exp()\n",
    "        # This is different than in the previous lab. Avoiding for loops here.\n",
    "        denominators = exp_inputs.sum(1).repeat(inputs.size(1), 1).t()\n",
    "        self.predictions = torch.mul(exp_inputs, 1 / denominators)\n",
    "        # Check what gather does. Just avoiding another for loop.\n",
    "        return -self.predictions.log().gather(1, labels.view(-1, 1)).mean()\n",
    "    \n",
    "    # Backward pass \n",
    "    def backward(self, inputs, labels):\n",
    "        grad_inputs = self.predictions.clone()\n",
    "        # Ok, Here we will use a for loop (but it is avoidable too).\n",
    "        for i in range(0, inputs.size(0)):\n",
    "            grad_inputs[i][labels[i]] = grad_inputs[i][labels[i]] - 1\n",
    "        return grad_inputs \n",
    "\n",
    "# Input: 4 vectors of size 10.\n",
    "testInput = torch.Tensor(4, 10).normal_(0, 0.1)\n",
    "# labels: 4 labels indicating the correct class for each input.\n",
    "labels = torch.LongTensor([3, 4, 4, 8])\n",
    "\n",
    "# Forward and Backward passes:\n",
    "loss_softmax = nn_CrossEntropyLoss()\n",
    "loss = loss_softmax.forward(testInput, labels)\n",
    "gradInputs = loss_softmax.backward(testInput, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing, make sure you understand every line of code in the above implementation by looking at previous lecture notes. \n",
    "\n",
    "### 2. Implementing our own Linear layer.\n",
    "Next we provide an implementation for a linear layer that is also meant to work on batches of vetors. Notice that in addition of computing gradWeight and gradBias, we require here gradInput as we might need this gradient to do backpropagation. Making a batched implementation of this layer is easier because the only change is that now we have matrix-matrix multiplications as opposed to vector-matrix multiplications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class nn_Linear(object):\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        self.weight = torch.Tensor(inputSize, outputSize).normal_(0, 0.01)\n",
    "        self.gradWeight = torch.Tensor(inputSize, outputSize)\n",
    "        self.bias = torch.Tensor(outputSize).zero_()\n",
    "        self.gradBias = torch.Tensor(outputSize)\n",
    "    \n",
    "    # Forward pass, inputs is a matrix of size batchSize x inputSize\n",
    "    def forward(self, inputs):\n",
    "        # This one needs no change, it just becomes matrix x matrix multiplication\n",
    "        # as opposed to just vector x matrix multiplication as we had before.\n",
    "        return torch.matmul(inputs, self.weight) + self.bias\n",
    "    \n",
    "    # Backward pass, in addition to compute gradients for the weight and bias.\n",
    "    # It has to compute gradients with respect to inputs. \n",
    "    def backward(self, inputs, gradOutput):\n",
    "        self.gradWeight = torch.matmul(inputs.t(), gradOutput)\n",
    "        self.gradBias = gradOutput.sum(0)\n",
    "        return torch.matmul(gradOutput, self.weight.t())\n",
    "\n",
    "# Input: 4 vectors of size 3072.\n",
    "testInput = torch.Tensor(4, 3 * 32 * 32).normal_(0, 0.1)\n",
    "dummyGradOutputs = torch.Tensor(4, 10).normal_(0, 0.1)\n",
    "\n",
    "#Forward and Backward passes:\n",
    "linear = nn_Linear(3 * 32 * 32, 10)\n",
    "output = linear.forward(testInput)\n",
    "gradInput = linear.backward(testInput, dummyGradOutputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implementing an \"Activation\" function, or non-linearity.\n",
    "Finally we need to implement some non-linear activation function. Here we will implement ReLU which is the simplest activation function but also one of the most important as we discussed during class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class nn_ReLU(object):\n",
    "    # pytorch has an element-wise max function.\n",
    "    def forward(self, inputs):\n",
    "        outputs = inputs.clone()\n",
    "        outputs[outputs < 0] = 0\n",
    "        return outputs\n",
    "    \n",
    "    # Make sure the backward pass is absolutely clear.\n",
    "    def backward(self, inputs, gradOutput):\n",
    "        gradInputs = gradOutput.clone()\n",
    "        gradInputs[inputs < 0] = 0\n",
    "        return gradInputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Implementation I: CIFAR-10 Neural network classification using our implementations.\n",
    "Ok, now we are ready to use our three layers to build a neural network. We will use it to classify images on CIFAR-10 as in our previous lab, but additionally we will use pytorch's DataLoaders which will build batches automatically for us, and will shuffle the data for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In addition to transforming the image into a tensor, we also normalize the values in the image\n",
    "# so that the mean pixel value is subtracted and divided by the pixel standard deviation.\n",
    "imgTransform = transforms.Compose([transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                                                        (0.2023, 0.1994, 0.2010)),\n",
    "                                   transforms.Lambda(lambda inputs: inputs.view(3 * 32 * 32))])\n",
    "trainset = CIFAR10(root='./data', train = True, transform = imgTransform)\n",
    "valset = CIFAR10(root='./data', train = False, transform = imgTransform)\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(trainset, batch_size = 128, \n",
    "                                          shuffle = True, num_workers = 0)\n",
    "valLoader = torch.utils.data.DataLoader(valset, batch_size = 128, \n",
    "                                        shuffle = False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dataset train, and validation splits are loaded, let's train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0: 100%|██████████| 391/391 [00:25<00:00, 15.36it/s, accuracy=37.3, loss=1.8] \n",
      "Validation epoch 0: 100%|██████████| 79/79 [00:02<00:00, 34.31it/s, accuracy=43.4, loss=1.64]\n",
      "Training epoch 1: 100%|██████████| 391/391 [00:24<00:00, 15.78it/s, accuracy=44.8, loss=1.59]\n",
      "Validation epoch 1: 100%|██████████| 79/79 [00:02<00:00, 33.82it/s, accuracy=45.7, loss=1.55]\n",
      "Training epoch 2: 100%|██████████| 391/391 [00:24<00:00, 15.71it/s, accuracy=48, loss=1.5]   \n",
      "Validation epoch 2: 100%|██████████| 79/79 [00:02<00:00, 34.78it/s, accuracy=48.4, loss=1.49]\n",
      "Training epoch 3: 100%|██████████| 391/391 [00:24<00:00, 16.08it/s, accuracy=50.5, loss=1.43]\n",
      "Validation epoch 3: 100%|██████████| 79/79 [00:02<00:00, 35.16it/s, accuracy=49.2, loss=1.45]\n",
      "Training epoch 4: 100%|██████████| 391/391 [00:24<00:00, 15.74it/s, accuracy=52.5, loss=1.38]\n",
      "Validation epoch 4: 100%|██████████| 79/79 [00:02<00:00, 33.82it/s, accuracy=50.5, loss=1.42]\n",
      "Training epoch 5: 100%|██████████| 391/391 [00:24<00:00, 15.67it/s, accuracy=54.3, loss=1.33]\n",
      "Validation epoch 5: 100%|██████████| 79/79 [00:02<00:00, 34.02it/s, accuracy=51.1, loss=1.4] \n",
      "Training epoch 6: 100%|██████████| 391/391 [00:24<00:00, 15.69it/s, accuracy=55.8, loss=1.28]\n",
      "Validation epoch 6: 100%|██████████| 79/79 [00:02<00:00, 35.50it/s, accuracy=51.4, loss=1.38]\n",
      "Training epoch 7: 100%|██████████| 391/391 [00:24<00:00, 15.94it/s, accuracy=57.4, loss=1.24]\n",
      "Validation epoch 7: 100%|██████████| 79/79 [00:02<00:00, 34.06it/s, accuracy=52.5, loss=1.36]\n",
      "Training epoch 8: 100%|██████████| 391/391 [00:24<00:00, 15.75it/s, accuracy=59, loss=1.2]   \n",
      "Validation epoch 8: 100%|██████████| 79/79 [00:02<00:00, 33.76it/s, accuracy=52.7, loss=1.35]\n",
      "Training epoch 9: 100%|██████████| 391/391 [00:24<00:00, 16.73it/s, accuracy=60.6, loss=1.17]\n",
      "Validation epoch 9: 100%|██████████| 79/79 [00:02<00:00, 34.21it/s, accuracy=52.5, loss=1.35]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm as tqdm\n",
    "# Try this if the above gives trouble: from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "learningRate = 1e-4  # Single learning rate for this lab.\n",
    "\n",
    "# Definition of our network.\n",
    "linear1 = nn_Linear(3 * 32 * 32, 1024)\n",
    "relu = nn_ReLU()\n",
    "linear2 = nn_Linear(1024, 10)\n",
    "criterion = nn_CrossEntropyLoss()\n",
    "\n",
    "# Training loop.\n",
    "for epoch in range(0, 10):\n",
    "    correct = 0.0\n",
    "    cum_loss = 0.0\n",
    "    counter = 0\n",
    "    \n",
    "    # Make a pass over the training data.\n",
    "    t = tqdm(trainLoader, desc = 'Training epoch %d' % epoch)\n",
    "    for (i, (inputs, labels)) in enumerate(t):\n",
    "    \n",
    "        # Forward pass:\n",
    "        a = linear1.forward(inputs)\n",
    "        b = relu.forward(a)\n",
    "        c = linear2.forward(b)\n",
    "        cum_loss += criterion.forward(c, labels)\n",
    "        max_scores, max_labels = c.max(1)\n",
    "        correct += (max_labels == labels).sum()\n",
    "        \n",
    "        # Backward pass:\n",
    "        grads_c = criterion.backward(c, labels)\n",
    "        grads_b = linear2.backward(b, grads_c)\n",
    "        grads_a = relu.backward(a, grads_b)\n",
    "        linear1.backward(inputs, grads_a)\n",
    "        \n",
    "        # Weight and bias updates.\n",
    "        linear1.weight = linear1.weight - learningRate * linear1.gradWeight\n",
    "        linear1.bias = linear1.bias - learningRate * linear1.gradBias\n",
    "        linear2.weight = linear2.weight - learningRate * linear2.gradWeight\n",
    "        linear2.bias = linear2.bias - learningRate * linear2.gradBias\n",
    "        \n",
    "        # logging information.\n",
    "        counter += inputs.size(0)\n",
    "        t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n",
    "    \n",
    "    # Make a pass over the validation data.\n",
    "    correct = 0.0\n",
    "    cum_loss = 0.0\n",
    "    counter = 0\n",
    "    t = tqdm(valLoader, desc = 'Validation epoch %d' % epoch)\n",
    "    for (i, (inputs, labels)) in enumerate(t):\n",
    "        \n",
    "        # Forward pass:\n",
    "        a = linear1.forward(inputs)\n",
    "        b = relu.forward(a)\n",
    "        c = linear2.forward(b)\n",
    "        cum_loss += criterion.forward(c, labels)\n",
    "        max_scores, max_labels = c.max(1)\n",
    "        correct += (max_labels == labels).sum()\n",
    "        \n",
    "        # logging information.\n",
    "        counter += inputs.size(0)\n",
    "        t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Implementation II: CIFAR-10 neural network classification using pytorch's nn functions.\n",
    "Pytorch already comes with an impressive number of operations used to implement deep neural networks. Here we will use the same ones that we already have implemented and show how similar and easy is to use pytorch's implementations. Another thing about pytorch is that we will wrap our variables in a neural network with a torch.autograd.Variable object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0: 100%|██████████| 391/391 [00:18<00:00, 20.89it/s, accuracy=38.2, loss=1.77]\n",
      "Validation epoch 0: 100%|██████████| 79/79 [00:02<00:00, 34.01it/s, accuracy=43.9, loss=1.62]\n",
      "Training epoch 1: 100%|██████████| 391/391 [00:18<00:00, 20.72it/s, accuracy=45.7, loss=1.57]\n",
      "Validation epoch 1: 100%|██████████| 79/79 [00:02<00:00, 34.73it/s, accuracy=45.8, loss=1.54]\n",
      "Training epoch 2: 100%|██████████| 391/391 [00:18<00:00, 20.98it/s, accuracy=48.6, loss=1.49]\n",
      "Validation epoch 2: 100%|██████████| 79/79 [00:02<00:00, 33.71it/s, accuracy=47.7, loss=1.49]\n",
      "Training epoch 3: 100%|██████████| 391/391 [00:19<00:00, 21.46it/s, accuracy=51, loss=1.43]  \n",
      "Validation epoch 3: 100%|██████████| 79/79 [00:02<00:00, 34.00it/s, accuracy=49.2, loss=1.46]\n",
      "Training epoch 4: 100%|██████████| 391/391 [00:19<00:00, 20.30it/s, accuracy=53, loss=1.37]  \n",
      "Validation epoch 4: 100%|██████████| 79/79 [00:02<00:00, 33.92it/s, accuracy=50.3, loss=1.42]\n",
      "Training epoch 5: 100%|██████████| 391/391 [00:18<00:00, 20.79it/s, accuracy=54.6, loss=1.33]\n",
      "Validation epoch 5: 100%|██████████| 79/79 [00:02<00:00, 34.43it/s, accuracy=50.9, loss=1.4] \n",
      "Training epoch 6: 100%|██████████| 391/391 [00:19<00:00, 20.99it/s, accuracy=55.9, loss=1.29]\n",
      "Validation epoch 6: 100%|██████████| 79/79 [00:02<00:00, 34.13it/s, accuracy=51.6, loss=1.39]\n",
      "Training epoch 7: 100%|██████████| 391/391 [00:19<00:00, 20.28it/s, accuracy=57.5, loss=1.25]\n",
      "Validation epoch 7: 100%|██████████| 79/79 [00:02<00:00, 33.89it/s, accuracy=51.8, loss=1.37]\n",
      "Training epoch 8: 100%|██████████| 391/391 [00:19<00:00, 20.93it/s, accuracy=58.9, loss=1.21]\n",
      "Validation epoch 8: 100%|██████████| 79/79 [00:02<00:00, 33.72it/s, accuracy=52.1, loss=1.36]\n",
      "Training epoch 9: 100%|██████████| 391/391 [00:19<00:00, 20.40it/s, accuracy=60.2, loss=1.18]\n",
      "Validation epoch 9: 100%|██████████| 79/79 [00:02<00:00, 32.50it/s, accuracy=52.7, loss=1.35]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm as tqdm\n",
    "# Try this if the above gives trouble: from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "learningRate = 1e-2  # Single learning rate for this lab.\n",
    "\n",
    "# Definition of our network.\n",
    "network = nn.Sequential(\n",
    "    nn.Linear(3072, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 10),\n",
    ")\n",
    "#Definition of our loss.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Definition of optimization strategy.\n",
    "optimizer = optim.SGD(network.parameters(), lr = learningRate)\n",
    "\n",
    "def train_model(network, criterion, optimizer, trainLoader, valLoader, n_epochs = 10):\n",
    "    # Training loop.\n",
    "    for epoch in range(0, n_epochs):\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "\n",
    "        # Make a pass over the training data.\n",
    "        t = tqdm(trainLoader, desc = 'Training epoch %d' % epoch)\n",
    "        network.train()  # This is important to call before training!\n",
    "        for (i, (inputs, labels)) in enumerate(t):\n",
    "\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(inputs)\n",
    "            labels = Variable(labels)\n",
    "\n",
    "            # Forward pass:\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass:\n",
    "            optimizer.zero_grad()\n",
    "            # Loss is a variable, and calling backward on a Variable will\n",
    "            # compute all the gradients that lead to that Variable taking on its\n",
    "            # current value.\n",
    "            loss.backward() \n",
    "\n",
    "            # Weight and bias updates.\n",
    "            optimizer.step()\n",
    "\n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            max_scores, max_labels = outputs.data.max(1)\n",
    "            correct += (max_labels == labels.data).sum()\n",
    "            counter += inputs.size(0)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n",
    "\n",
    "        # Make a pass over the validation data.\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "        t = tqdm(valLoader, desc = 'Validation epoch %d' % epoch)\n",
    "        network.eval()  # This is important to call before evaluating!\n",
    "        for (i, (inputs, labels)) in enumerate(t):\n",
    "\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(inputs)\n",
    "            labels = Variable(labels)\n",
    "\n",
    "            # Forward pass:\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            max_scores, max_labels = outputs.data.max(1)\n",
    "            correct += (max_labels == labels.data).sum()\n",
    "            counter += inputs.size(0)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)  \n",
    "            \n",
    "# Train the previously defined model.\n",
    "train_model(network, criterion, optimizer, trainLoader, valLoader, n_epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 5. Implementation III: CIFAR-10 neural network classification using pytorch's autograd magic!\n",
    "Objects of type torch.autograd.Variable contain two attributes .data and .grad, the first one, .data, contains the value of the variable at any given point, and .grad contains the value of the gradient of this variable once a backward call involving this variable has been invoked. In the previous code, we have to take into account that most torch tensor operations that can be applied to tensors, can also be applied to tensors wrapped into torch.autograd.Variables. The output of torch operations involving variables will also be a torch.autograd.Variable (as opposed to just a tensor). Another difference is that pytorch will record the operations on each torch.autograd.Variable in a graph structure so that gradients can be computed when a backward() call is performed on any variable in the graph. This very powerful technique is often called \"automatic differentiation\". This means that as long as we wrap tensors in variables, and use pytorch operators, we do not really need to implement backward passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0: 100%|██████████| 391/391 [00:19<00:00, 20.33it/s, accuracy=36, loss=1.83]  \n",
      "Validation epoch 0: 100%|██████████| 79/79 [00:02<00:00, 33.73it/s, accuracy=41.9, loss=1.67]\n",
      "Training epoch 1: 100%|██████████| 391/391 [00:19<00:00, 21.00it/s, accuracy=43.8, loss=1.62]\n",
      "Validation epoch 1: 100%|██████████| 79/79 [00:02<00:00, 33.80it/s, accuracy=45.6, loss=1.57]\n",
      "Training epoch 2: 100%|██████████| 391/391 [00:19<00:00, 21.05it/s, accuracy=46.8, loss=1.53]\n",
      "Validation epoch 2: 100%|██████████| 79/79 [00:02<00:00, 34.19it/s, accuracy=47, loss=1.52]  \n",
      "Training epoch 3: 100%|██████████| 391/391 [00:19<00:00, 20.88it/s, accuracy=49.1, loss=1.47]\n",
      "Validation epoch 3: 100%|██████████| 79/79 [00:02<00:00, 33.80it/s, accuracy=48.8, loss=1.48]\n",
      "Training epoch 4: 100%|██████████| 391/391 [00:19<00:00, 20.49it/s, accuracy=51.1, loss=1.42]\n",
      "Validation epoch 4: 100%|██████████| 79/79 [00:02<00:00, 33.85it/s, accuracy=49.7, loss=1.45]\n",
      "Training epoch 5: 100%|██████████| 391/391 [00:19<00:00, 20.36it/s, accuracy=52.8, loss=1.37]\n",
      "Validation epoch 5: 100%|██████████| 79/79 [00:02<00:00, 34.02it/s, accuracy=50.2, loss=1.42]\n",
      "Training epoch 6: 100%|██████████| 391/391 [00:18<00:00, 20.61it/s, accuracy=54.3, loss=1.33]\n",
      "Validation epoch 6: 100%|██████████| 79/79 [00:02<00:00, 34.15it/s, accuracy=51, loss=1.4]   \n",
      "Training epoch 7: 100%|██████████| 391/391 [00:19<00:00, 20.47it/s, accuracy=55.8, loss=1.29]\n",
      "Validation epoch 7: 100%|██████████| 79/79 [00:02<00:00, 34.14it/s, accuracy=51.8, loss=1.38]\n",
      "Training epoch 8: 100%|██████████| 391/391 [00:19<00:00, 20.49it/s, accuracy=57.1, loss=1.26]\n",
      "Validation epoch 8: 100%|██████████| 79/79 [00:02<00:00, 33.43it/s, accuracy=51.8, loss=1.37]\n",
      "Training epoch 9: 100%|██████████| 391/391 [00:19<00:00, 20.40it/s, accuracy=58.1, loss=1.23]\n",
      "Validation epoch 9: 100%|██████████| 79/79 [00:02<00:00, 33.44it/s, accuracy=52.4, loss=1.36]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm as tqdm\n",
    "# Try this if the above gives trouble: from tqdm import tqdm_notebook as tqdm\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "learningRate = 1e-2  # Single learning rate for this lab.\n",
    "\n",
    "class MyAutogradModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyAutogradModel, self).__init__()\n",
    "        # See documentation for nn.Parameter here:\n",
    "        # https://github.com/pytorch/pytorch/blob/master/torch/nn/parameter.py\n",
    "        self.weight1 = nn.Parameter(torch.Tensor(3072, 1024).normal_(0, 0.01))\n",
    "        self.bias1 = nn.Parameter(torch.Tensor(1024).zero_())\n",
    "        self.weight2 = nn.Parameter(torch.Tensor(1024, 10).normal_(0, 0.01))\n",
    "        self.bias2 = nn.Parameter(torch.Tensor(10).zero_())\n",
    "        \n",
    "    # No need to implement backward when using torch.autograd.Variable and pytorch functions.\n",
    "    # Think of the possibilities!\n",
    "    def forward(self, inputs):\n",
    "        x = F.relu(torch.matmul(inputs, self.weight1) + self.bias1)\n",
    "        x = torch.matmul(x, self.weight2) + self.bias2\n",
    "        return x\n",
    "        \n",
    "# Definition of our network.\n",
    "network = MyAutogradModel()\n",
    "\n",
    "#Definition of our loss.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Definition of optimization strategy.\n",
    "optimizer = optim.SGD(network.parameters(), lr = learningRate)\n",
    "\n",
    "# Train the previously defined model.\n",
    "train_model(network, criterion, optimizer, trainLoader, valLoader, n_epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Convolutional Neural Networks (using Pytorch nn's)\n",
    "In this section we will use convolutional layers in addition to linear layers. Convolutional layers work on 2D input so we will modify our data loaders so that they return 2D images instead of the flattened array versions of the images that we have been using thus far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Same transformations as before but we do not vectorize the images.\n",
    "imgTransform = transforms.Compose([transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                                                        (0.2023, 0.1994, 0.2010))])\n",
    "trainset = CIFAR10(root='./data', train = True, transform = imgTransform)\n",
    "valset = CIFAR10(root='./data', train = False, transform = imgTransform)\n",
    "\n",
    "trainLoader128 = torch.utils.data.DataLoader(trainset, batch_size = 128, \n",
    "                                          shuffle = True, num_workers = 0)\n",
    "valLoader128 = torch.utils.data.DataLoader(valset, batch_size = 128, \n",
    "                                        shuffle = False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once data is loaded, now we proceed to define and train our neural network. Notice how we only need to change the definition of the model and not the way it is trained. This is just another of many advantages of training with a framework built on well engineered practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd8f98d24b247888bbe322d16dcddee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540605d916244145b6dc5a81229e3ca3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca231450098490bac8ab3e57d8b84b2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23903cfaa414444836a721528741e46"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f4cee124dec47a3a32bff18976c95a0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319f9bbb571b4f09b2df5f556f9a34cf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60492812a1f4e119f85e985dcbf2b5d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3a6294c6834f22aee8f4d6b06f22a8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee87a9b5d904f3a990dd141e33440a3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33ecf46660043e7bd417530d7605f43"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20ed721483e43bf8ed3256a3b9cca70"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac90ad86ca94a6db07cdd05837c42be"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8308afcbd847bba62590684b87e207"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5159e9cd2b84dfcbb92276b426b7666"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d71a801bf6743f39bd0c45046507ea3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d92b9e8a074ce687c60d31f9239033"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62d2e029ae24424c8850d0f482695892"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca03450df684fa2b86647f0a20eaa9b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eed8f71466f456ba94897b441a51f1f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b374aeba8bc248fabc45c70ff57f832c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7e00434fdf47a3b01fcb19891a14b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9556ebc03814490a27b8584a3f5a76f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f0e8595edb4999ac3ae15071f9d4eb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "746600d502bd45ceaa4058ea4fc33b91"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ec01692ba54a2bb304b398fbbc1142"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525a9bc138e4480a965c170cbdec4a04"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb963eacf19c4155959cb030a320f34a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bebbcaa50a2940db86e21f0b5255846f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3485e3a9aa940be8047cffebc7dd47f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm as tqdm\n",
    "# Try this if the above gives trouble: from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "learningRate = 1e-2  # Single learning rate for this lab.\n",
    "\n",
    "# LeNet is French for The Network, and is taken from Yann Lecun's 98 paper\n",
    "# on digit classification http://yann.lecun.com/exdb/lenet/\n",
    "# This was also a network with just two convolutional layers.\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # Convolutional layers.\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        # Linear layers.\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        \n",
    "        # This flattens the output of the previous layer into a vector.\n",
    "        out = out.view(out.size(0), -1) \n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "        \n",
    "        \n",
    "# Definition of our network.\n",
    "network = LeNet()\n",
    "\n",
    "#Definition of our loss.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Definition of optimization strategy.\n",
    "optimizer = optim.SGD(network.parameters(), lr = learningRate)\n",
    "\n",
    "# Train the previously defined model.\n",
    "train_model(network, criterion, optimizer, trainLoader128, valLoader128, n_epochs = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last model achieved some more impressive numbers than the 40% we were obtaining in our previous lab by a large margin. The last model seems to be still improving, maybe training it for more epochs, or under a different learning rate, or reducing the learning rate after the first 20 epochs, could improve the accuracy further. We could try all these things. We should also from time to time, test our model on a few inputs and see how good it is becoming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "un_normalize = lab_utils.UnNormalize((0.4914, 0.4822, 0.4465), \n",
    "                                     (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "network.eval()  # Important!\n",
    "\n",
    "# Now predict the category using this trained classifier\n",
    "for i in range(0, 5):\n",
    "    img_id = random.randint(0, 10000)\n",
    "    print('Image %d' % img_id)\n",
    "    img, _ = valset[img_id]\n",
    "    predictions = F.softmax(network(Variable(img.unsqueeze(0))))\n",
    "    predictions = predictions.data\n",
    "\n",
    "    # Show the results of the classifier.\n",
    "    lab_utils.show_image(lab_utils.tensor2pil(un_normalize(img)).resize((128, 128)));\n",
    "    max_score, max_label = predictions.max(1)\n",
    "    print('Image predicted as %s with confidence %.2f' % (classes[max_label[0]], max_score[0]))\n",
    "\n",
    "    # Print out detailed predictions.\n",
    "    for (i, pred) in enumerate(predictions.squeeze().tolist()):\n",
    "        print('y_hat[%s] = %.2f' % (classes[i], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Pytorch's pretrained Convolutional Neural Networks.\n",
    "Pytorch has several pretrained Convnet models in the Imagenet Large Scale Visual Recognition Challenge (ILSVRC) dataset. The ILSVRC task contains more than 1 million images in the training set, and the number of labels is 1000. Training a Convnet on this dataset takes often weeks on arrays of GPUs. Let's load one of such networks with 18 layers of depth, and try it in some images. Look below at how impressive is this neural network with so many layers and groups of layers, however most layers are still ReLU, Conv2d, and BatchNorm2d, with a few MaxPool2d, and one AvgPool2d and Linear at the end. There are also Resnet versions of depth size 34, 50, 101, and 152."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet = models.resnet18(pretrained = True)\n",
    "print(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Define the appropriate image pre-processing function.\n",
    "preprocessFn = transforms.Compose([transforms.Scale(256), \n",
    "                                   transforms.CenterCrop(224), \n",
    "                                   transforms.ToTensor(), \n",
    "                                   transforms.Normalize(mean = [0.485, 0.456, 0.406], \n",
    "                                                        std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# 2. Load the imagenet class names.\n",
    "imagenetClasses = {int(idx): entry[1] for (idx, entry) in json.load(open('imagenet_class_index.json')).items()}\n",
    "\n",
    "# 3. Forward a test image of the toaster.\n",
    "# Never forget to set in evaluation mode so Dropoff layers don't add randomness.\n",
    "resnet.eval()\n",
    "# unsqueeze(0) adds a dummy batch dimension which is required for all models in pytorch.\n",
    "image = Image.open('test_image.jpg').convert('RGB')\n",
    "# Try your own image here. This is a picture of my toaster at home.\n",
    "inputVar =  Variable(preprocessFn(image).unsqueeze(0))\n",
    "predictions = resnet(inputVar)\n",
    "\n",
    "# 4. Decode the top 10 classes predicted for this image.\n",
    "# We need to apply softmax because the model outputs the last linear layer activations and not softmax scores.\n",
    "probs, indices = (-F.softmax(predictions)).data.sort()\n",
    "probs = (-probs).numpy()[0][:10]; indices = indices.numpy()[0][:10]\n",
    "preds = [imagenetClasses[idx] + ': ' + str(prob) for (prob, idx) in zip(probs, indices)]\n",
    "\n",
    "# 5. Show image and predictions\n",
    "plt.title(string.join(preds, '\\n'))\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Fine-tuning Resnet on CIFAR-10\n",
    "\n",
    "We will now use a pretrained network known as Alexnet on CIFAR-10 data, however there is a problem which is that Alexnet takes images in 224x224 resolution, and CIFAR-10 images are 32x32. So we will scale-up images in CIFAR-10 so that they work with Alexnet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Same transformations as before but we do not vectorize the images.\n",
    "# Additionally we are scaling up images to 224x224 in order to use Resnet.\n",
    "imgTransform = transforms.Compose([transforms.Scale((224, 224)),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                                                        (0.2023, 0.1994, 0.2010))])\n",
    "trainset = CIFAR10(root='./data', train = True, transform = imgTransform)\n",
    "valset = CIFAR10(root='./data', train = False, transform = imgTransform)\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(trainset, batch_size = 64, \n",
    "                                          shuffle = True, num_workers = 0)\n",
    "valLoader = torch.utils.data.DataLoader(valset, batch_size = 64, \n",
    "                                        shuffle = False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will be extremely slow on a CPU, hours per epoch, and maybe a week to finish all epochs. For this part yu will need GPU nodes in the cloud (AWS, Google Cloud) or your own GPU. Another thing, is that GPUs do not have a lot of memory so batch size 128 is also not going to be possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm as tqdm\n",
    "# Try this if the above gives trouble: from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "learningRate = 1e-3  # Single learning rate for this lab.\n",
    "\n",
    "# Definition of our network.\n",
    "network = models.alexnet(pretrained = True)\n",
    "network.fc = nn.Linear(2048, 10)  # CIFAR-10 has 10 classes not 1000.\n",
    "\n",
    "#Definition of our loss.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Definition of optimization strategy.\n",
    "optimizer = optim.SGD(network.parameters(), lr = learningRate)\n",
    "\n",
    "def train_model(network, criterion, optimizer, trainLoader, valLoader, n_epochs = 10, use_gpu = False):\n",
    "    if use_gpu:\n",
    "        network = network.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        \n",
    "    # Training loop.\n",
    "    for epoch in range(0, n_epochs):\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "\n",
    "        # Make a pass over the training data.\n",
    "        t = tqdm(trainLoader, desc = 'Training epoch %d' % epoch)\n",
    "        network.train()  # This is important to call before training!\n",
    "        for (i, (inputs, labels)) in enumerate(t):\n",
    "\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(inputs)\n",
    "            labels = Variable(labels)\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # Forward pass:\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass:\n",
    "            optimizer.zero_grad()\n",
    "            # Loss is a variable, and calling backward on a Variable will\n",
    "            # compute all the gradients that lead to that Variable taking on its\n",
    "            # current value.\n",
    "            loss.backward() \n",
    "\n",
    "            # Weight and bias updates.\n",
    "            optimizer.step()\n",
    "\n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            max_scores, max_labels = outputs.data.max(1)\n",
    "            correct += (max_labels == labels.data).sum()\n",
    "            counter += inputs.size(0)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n",
    "\n",
    "        # Make a pass over the validation data.\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "        t = tqdm(valLoader, desc = 'Validation epoch %d' % epoch)\n",
    "        network.eval()  # This is important to call before evaluating!\n",
    "        for (i, (inputs, labels)) in enumerate(t):\n",
    "\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(inputs)\n",
    "            labels = Variable(labels)\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # Forward pass:\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            max_scores, max_labels = outputs.data.max(1)\n",
    "            correct += (max_labels == labels.data).sum()\n",
    "            counter += inputs.size(0)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n",
    "            \n",
    "# Train the previously defined model.\n",
    "train_model(network, criterion, optimizer, trainLoader, valLoader, n_epochs = 10, use_gpu = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Questions (10pts)\n",
    "\n",
    "1) [2pts] In section 3 of this lab we implemented the ReLU activation function, and used it to train a two-layer neural network. Here please implement Sigmoid, and TanH:\n",
    "\n",
    "$$\\text{Sigmoid(x)} = \\frac{1}{1 + e^{-x}} = \\frac{e^x}{e^x + 1}$$\n",
    "\n",
    "$$\\text{Tanh(x)} = \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sigmoid of x.\n",
    "class nn_Sigmoid:\n",
    "    def forward(self, x):\n",
    "        # Forward pass.\n",
    "        pass\n",
    "    \n",
    "    def backward(self, x, gradOutput):\n",
    "        # Backward pass\n",
    "        pass\n",
    "        \n",
    "# Hyperbolic tangent.\n",
    "class nn_Tanh:\n",
    "    def forward(self, x):\n",
    "        # Forward pass.\n",
    "        pass\n",
    "    \n",
    "    def backward(self, x, gradOutput):\n",
    "        # Backward pass\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) [1pts] Our ReLU function makes things zero when they are less than zero. This is still the most widely used activation function used today but a variante called LeakyReLU has been proposed where a linear function close to zero is used instead. Here is the definition:\n",
    "\n",
    "$$ \\text{LeakyReLU}(x) = \\begin{cases} \n",
    "      \\beta x & x < 0 \\\\\n",
    "      x & x \\geq 0 \n",
    "\\end{cases}$$\n",
    "\n",
    "where $\\beta$ is usally a small value e.g. $\\beta = 0.3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sigmoid of x.\n",
    "class nn_LeakyReLU:\n",
    "    def __init__(self, beta = 0.3):\n",
    "        self.beta = beta\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Forward pass.\n",
    "        pass\n",
    "    \n",
    "    def backward(self, x, gradOutput):\n",
    "        # Backward pass\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) [3pts] Propose a new convolutional neural network that obtains at least 66% accuracy in the CIFAR-10 validation set. Show here the code for your network, and a plot showing the training accuracy, validation accuracy, and another one with the training loss, and validation loss (similar plots as in our previous lab). Included is below the LeNet implementation that you can use as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm as tqdm\n",
    "# Try this if the above gives trouble: from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "learningRate = 1e-2  # Feel free to change this.\n",
    "\n",
    "# You can use LeNet as the starting point.\n",
    "# You can do things such as adding more layers,\n",
    "# adding more filters to the existing layers, \n",
    "# adding things such as BatchNormalization, Dropout, etc.\n",
    "# anything you want, but add references if you consult something online.\n",
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # Convolutional layers.\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        # Linear layers.\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        \n",
    "        # This flattens the output of the previous layer into a vector.\n",
    "        out = out.view(out.size(0), -1) \n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "        \n",
    "        \n",
    "# Definition of our network.\n",
    "network = MyNetwork()\n",
    "\n",
    "# Feel free to use a different loss here.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Feel free to change the optimizer, or the optimizer parameters. e.g. momentum, weightDecay, etc.\n",
    "optimizer = optim.SGD(network.parameters(), lr = learningRate)\n",
    "\n",
    "# Train the previously defined model.\n",
    "train_model(network, criterion, optimizer, trainLoader, valLoader, n_epochs = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) [4pts] Train a Convolutional Neural Network on the Dogs vs Cats Kaggle competition dataset https://www.kaggle.com/c/dogs-vs-cats. The training data has 25,000 images, I already separated the images into training: 20,000 images and validation: 5,000 images. So please download the training, validation splits from the following dropbox link instead: [cats_dogs.zip](https://www.dropbox.com/s/sg7q9hhdzdxoeh2/cats_dogs.zip?dl=0), or CS link: [cat_dogs.zip](http://www.cs.virginia.edu/~vicente/recognition/notebooks/cats_dogs.zip) . You will have to write your own dataset class inheriting from torch.utils.data.Dataset, and a model that trains on this dataset. As usual, include plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional\n",
    "\n",
    "1) [3pts] For Q4 you get extra points if you use Resnet as in Section 7 but replace the fc layer at the end so that the model only predicts two variables (cat and dog). You will have to then re-train Resnet in this dataset. The idea is to use a model that has already been pre-trained on large task (ILSVRC), and re-train it (often called fine-tuning), on a smaller dataset. Present your code for the model, training output, plots, and example classifications on a few validations set images. Note: If you provide a model that does this in Q4, you directly get awarded 7pts in Q4 but for clarity provide the solution here instead if you plan to do this. Keep in mind that re-training Resnet on 20,000 images will probably still require GPU computing, and some significant computing time so start this early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) [2pts] A simpler (less time consuming) approach to using a pre-trained CNN is to use it as a feature extractor. In this strategy we would use the Resnet network to compute \"features\" of the images, and then train a simple softmax classifier on top of those features. We could for instance remove the \"fc\" layer from the model, and use the 512-dimensional output of the network as our \"features\" for each image. Then we train a softmax classifier using these 512-dimensional vectors as inputs. Train such a classifier here for the dogs vs cats task, and present model, plots, and a few example classifications on the validation set. Note: In this task, since we only run the forward pass of Resnet once for each image, we might be able to get away doing this optional part without a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:0.8em;color:#888;text-align:center;padding-top:20px;\">If you find any errors or omissions in this material please contact me at vicente@virginia.edu</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
